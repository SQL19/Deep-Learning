{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Research Paper Recommendation System using SBERT\n",
        "The recommendation system will sugget a list of most similar papers for a given research paper."
      ],
      "metadata": {
        "id": "JuiwwZyI9V6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "psz-Tj3g-SQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import os\n",
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "ziMc3qfu_HaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Dataset"
      ],
      "metadata": {
        "id": "Benh68rj_rPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://sbert.net/datasets/emnlp2016-2018.json')\n",
        "papers = json.loads(response.text)"
      ],
      "metadata": {
        "id": "JgJzqgvJ_vZx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNOpL0n5_4lb",
        "outputId": "b673c545-5b6c-4a6b-9d47-ad8690491536"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'Rule Extraction for Tree-to-Tree Transducers by Cost Minimization',\n",
              " 'abstract': 'Finite-state transducers give efficient representations of many Natural Language phenomena. They allow to account for complex lexicon restrictions encountered, without involving the use of a large set of complex rules difficult to analyze. We here show that these representations can be made very compact, indicate how to perform the corresponding minimization, and point out interesting linguistic side-effects of this operation.',\n",
              " 'url': 'http://aclweb.org/anthology/D16-1002',\n",
              " 'venue': 'EMNLP',\n",
              " 'year': '2016'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSmq_B08_1l6",
        "outputId": "0213dcbf-9aac-4df5-e7e0-9e09ebbe8ac4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "974"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SBERT Model"
      ],
      "metadata": {
        "id": "eNigQ4o0ABu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we use the SPECTER model (https://arxiv.org/pdf/2004.07180.pdf)\n",
        "model = SentenceTransformer('allenai-specter')"
      ],
      "metadata": {
        "id": "hn2OBRRDAFLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encodes paper titles and abstracts\n",
        "paper_texts = [paper['title'] + '[SEP]' + paper['abstract'] for paper in papers]\n",
        "corpus_embeddings = model.encode(paper_texts, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "i5MuhVd5Ap8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(title, abstract):\n",
        "  query_embedding = model.encode(title + '[SEP]' + abstract, convert_to_tensor=True)\n",
        "\n",
        "  search_hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=3)[0]\n",
        "\n",
        "  print(\"Most Similar Papers\\n\")\n",
        "  for hit in search_hits:\n",
        "    related_paper = papers[hit['corpus_id']]\n",
        "    print(related_paper['title'])\n",
        "    print(related_paper['abstract'])\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "id": "39-88DIqBDPk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make recommendations\n",
        "title = 'Applications of big data in emerging management disciplines: A literature review using text mining'\n",
        "abstract = 'The importance of data-driven decisions and support is increasing day by day in every management area. The constant access to volume, variety, and veracity of data has made big data an integral part of management studies. New sub-management areas are emerging day by day with the support of big data to drive businesses. This study takes a systematic literature review approach to uncover the emerging management areas supported by big data in contemporary times. For this, we have analyzed the research papers published in the reputed management journals in the last ten years, fir using network analysis followed by natural language processing summarization techniques to find the emerging new management areas which are yet to get much attention. Furthermore, we ran the same exercise in each of these management areas to uncover these areas better. This research will act as a reference for future information systems (IS) scholars who want to perform analysis that is deep-dive in nature on each of these management areas, which in the coming times will get all the due attention to become dedicated research domains in the management area. We finally conclude the study by identifying the scope of future research in each of these management areas, which will be a true value addition for IS researchers.'\n",
        "search(title, abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9VPHjE8BxZ5",
        "outputId": "40986cc3-da60-4057-ab02-4e1988b05f88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Similar Papers\n",
            "\n",
            "Challenges of Using Text Classifiers for Causal Inference\n",
            "Causal understanding is essential for many kinds of decision-making, but causal inference from observational data has typically only been applied to structured, low-dimensional datasets. While text classifiers produce low-dimensional outputs, their use in causal inference has not previously been studied. To facilitate causal analyses based on language data, we consider the role that text classifiers can play in causal inference through established modeling mechanisms from the causality literature on missing data and measurement error. We demonstrate how to conduct causal analyses using text classifiers on simulated and Yelp data, and discuss the opportunities and challenges of future work that uses text data in causal inference.\n",
            "\n",
            "\n",
            "\n",
            "PubSE: A Hierarchical Model for Publication Extraction from Academic Homepages\n",
            "Despite recent evidence that Microsoft Academic is an extensive source of citation counts for journal articles, it is not known if the same is true for academic books. This paper fills this gap by comparing citations to 16,463 books from 2013-2016 in the Book Citation Index (BKCI) against automatically extracted citations from Microsoft Academic and Google Books in 17 fields. About 60% of the BKCI books had records in Microsoft Academic, varying by year and field. Citation counts from Microsoft Academic were 1.5 to 3.6 times higher than from BKCI in nine subject areas across all years for books indexed by both. Microsoft Academic found more citations than BKCI because it indexes more scholarly publications and combines citations to different editions and chapters. In contrast, BKCI only found more citations than Microsoft Academic for books in three fields from 2013-2014. Microsoft Academic also found more citations than Google Books in six fields for all years. Thus, Microsoft Academic may be a useful source for the impact assessment of books when comprehensive coverage is not essential.\n",
            "\n",
            "\n",
            "\n",
            "Fine-grained Coordinated Cross-lingual Text Stream Alignment for Endless Language Knowledge Acquisition\n",
            "Aligning coordinated text streams from multiple sources and multiple languages has opened many new research venues on cross-lingual knowledge discovery. In this paper we aim to advance state-of-the-art by: (1). extending coarse-grained topic-level knowledge mining to fine-grained information units such as entities and events; (2). following a novel Data-to-Network-to-Knowledge (D2N2K) paradigm to construct and utilize network structures to capture and propagate reliable evidence. We introduce a novel Burst Information Network (BINet) representation that can display the most important information and illustrate the connections among bursty entities, events and keywords in the corpus. We propose an effective approach to construct and decipher BINets, incorporating novel criteria based on multi-dimensional clues from pronunciation, translation, burst, neighbor and graph topological structure. The experimental results on Chinese and English coordinated text streams show that our approach can accurately decipher the nodes with high confidence in the BINets and that the algorithm can be efficiently run in parallel, which makes it possible to apply it to huge amounts of streaming data for never-ending language and information decipherment.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}